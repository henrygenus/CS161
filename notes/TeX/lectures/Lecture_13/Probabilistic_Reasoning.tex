\documentclass[../../lecture_notes.tex]{subfiles}

\begin{document}

\noindent Let’s motivate our study:\\
\\
Early AI was almost entirely logic-based, but in the 70s, a crisis emerged.\\
Classical logic is \textbf{\underline{monotonic}}, but human reasoning is not\\
\indent ($\equiv$ things that are true remain true with the introduction of new information)\\
\indent $((\Delta \models \alpha) \implies (\Delta \lor \beta \models \alpha))$\\

\noindent Consider the following example:\\
\indent Say you are told that Tweety is a bird ($\Delta$)\\
\indent Say you are asked “Does Tweety fly?” You would say yes ($\alpha$)\\
\indent But now say I tell you Tweety is a penguin  ($\Delta$)\\
\indent Now say you are asked “Does Tweety fly?” You would say no ($\neg\alpha$)\\
If we were to build this with first-order logic:\\
	\indent $\Delta: \forall$ x bird(x) $\implies$ flies (x)\\
	\indent \indent good: $\Delta \land$ bird(Tweety) $\models$ flies(Tweety)\\
	\indent \indent bad:  $\Delta \land$ bird(Tweety) $\land \neg$flies(Tweety) (CONTRADICTION)\\
We may thus conclude our information $\Delta$ was bad and do\\
	\indent $\Delta: \forall$ x bird(x) $\land$ abnormal(x) $\implies$ flies (x)\\
	\indent \indent good: $\Delta \land$ bird(Tweety) $\models$ flies(Tweety)\\
	\indent \indent bad:  $\Delta \land \neg$lies(Tweety) $\models_?$ flies(Tweety)\\
We therefore must assume abnormal is false unless we hear otherwise.\\
This is not classical logic! It involves assumptions!\\
Another abnormal logic type:\\
\indent $\Delta$ : Quaker(x) $\land \neg $ab(x) $\implies$ Pacifist(x)\\
\indent \indent Republican(x) $\land \neg$ab(x) $\implies \neg$Pacifist(x)\\
But Nixon is a Quaker Republican, he can’t both be and not be a pacifist!\\
Resolving this turns out to be complicated, and we will not address it; instead we introduce a new model:

\subsection*{Belief Revision}
\noindent We introduce the idea of degrees of belief in [0, 1]\\
We will use the same example as with logic:

\begin{center}\begin{minipage}{0.3\textwidth}
\begin{tabular} { | c | c | c | c | c | }\hline
	W & E & B & A & Pr(w)\\\hline
	1 & 1 & 1 & 1 & 0.0190\\\hline
	2 & 1 & 1 & 0 & 0.0010\\\hline
	3 & 1 & 0 & 1 & 0.0560\\\hline
	4 & 1 & 0 & 0 & 0.0240\\\hline
	5 & 0 & 1 & 1 & 0.1620\\\hline
	6 & 0 & 1 & 0 & 0.0180\\\hline
	7 & 0 & 0 & 1 & 0.0072\\\hline
	8 & 0 & 0 & 0 & 0.7128\\\hline
\end{tabular}\end{minipage}%
\begin{minipage}{0.7\textwidth}
\noindent Instead of ruling worlds in or out by entailment, we represent the chance of each world occurring.\\
\indent f: sentences $\rightarrow$ degree of certainty; $Pr(\alpha) = \sum Pr(w) \text{ for } w \models \alpha$\\
Therefore \begin{itemize} [itemsep=0mm]
	\item Pr(E) = 0.1
	\item $Pf(\neg E) = 1 - Pr(E) = 0.9$
	\item Pr(B) = 0.12
	\item $Pr(B \lor \neg E) = 1 - Pr(\neg B \land E) = 0.92$
\end{itemize}\end{minipage}\end{center}

\noindent We have a few properties that are required for probability to work:
	\begin{enumerate} [itemsep=0mm]
		\item $0 \leq Pr(\alpha) \leq 1$
		\item $\alpha$ is inconsistent $\iff Pr(\alpha) = 0$
		\item $\alpha$ is valid $\iff Pr(\alpha) = 1$
		\item $Pr(\alpha) + Pr(\neg\alpha) = 1$
		\item $Pr(\alpha\lor B) = Pr(A) + Pr(B) - Pr(\alpha \land B)$
		\item $If \ \alpha\ \&\ \beta$ are mutually exclusive, $Pr(\alpha\lor\beta) = Pr(\alpha) + Pr(\beta)$
	\end{enumerate}

\noindent Now how can we change beliefs with the introduction of new information?\\
Clearly, we must zero out any worlds that are invalid\\
P($\alpha | \beta$) = \[ \left\{ \begin{array} {lr}
				0 & \text{ if } w \models \neg\beta \\ 
				Pr(\alpha)/Pr(\beta) & \text{ if }w \models \beta  
			\end{array} \right\} \]
We can thus get \textbf{\underline{Bayes Condition}} \begin{equation*}
        Pr(\alpha | \beta) = \frac {Pr(\alpha\land\beta)} {Pr(\beta)} \end{equation*}
We apply this to the earlier example:\\
	\indent Pr(B) = 0.2, Pr(B|A) = 0.741\\
	\indent Pr(E) = 0.1, Pr(E|A) = 0.307\\
	\indent Pr(B) = 0.2, Pr(B|E) = 0.2\\
	\indent Pr(E) = 0.1, Pr(E|B) = 0.1\\
\\
We say two variables are \textbf{\underline{independent}} iff P(E) = P(E|B) \&\& P(B) = Pr(B|E)\\
Therefore we can see that B and E are independent in this system of belief.\\
\\
How does this gel when introducing a third?\\
	\indent Pr(B|A,E) = 0.253 < Pr(B|A)\\
	\indent Pr(B|A,¬E) = 0.957 > Pr(B|A)\\
While inapplicable this graph, Pr finds A \textbf{\underline{conditionally independent}} 
		iff $P(\alpha | B \land C) = P(\alpha | C)$.\\
This is equivalent to saying “B gives C”.\\
\\
Thus using these properties I can define a model of the world.\\
We have a few equations that can calculate all we need to know:
	\begin{enumerate} [itemsep=0mm]
		\item \textbf{\underline{Chain Rule}} $\equiv 
			Pr(e_1 \land e_2 \land ... \land e_n) = Pr(e_1 | e_2 \land e_3 \land ... \land e_n) + ... + Pr(en)$
		\item \textbf{\underline{Case Analysis}} $\equiv
			Pr(\alpha) = \sum Pr(\alpha\land\beta_i) = \sum Pr(\alpha | \beta_i) Pr(\alpha)$ where $\{\beta_i\}$
		\item \textbf{\underline{Bayes' Rule}} 
			$\equiv Pr(\alpha | \beta) = \frac {Pr(\alpha)}{Pr(\beta)} Pr(\beta|\alpha)$
	\end{enumerate} \medskip

\noindent This last rule is just a rework of Bayes' Condition, so why did he get credit for another rule?
The rule turns out to be incredibly useful; consider:\\
	\indent Say a patient gets a positive test for a disease (D)\\
	\indent Say we know P(D) = 1/1000\\
	\indent Say we know the false positive rate P(T|¬D) = 2\%\\
	\indent Say we know the false negative rate P(D|¬T) =5\%\\
	\indent We can use this to estimate the odds of the person having the disease!\\
	\indent \indent P(D|T) = (P(D)/P(T)) P(T+D) 
		= (P(T|D)P(D))/(P(T$\land\neg$B)P($\neg$D) * (1-P(D|$\neg$T))P(D)) = 4.5\%\\
\\
We have thus build a probability calculus on top of probability logic:\\
\indent To move on, we need to consider the fact that a variable can have multiple values\\
We can’t use our previous rules; this leads us to \textbf{\underline{equality}}
	$\equiv (x = grn) \lor (x = blue) \implies P(y=large)$


\end{document}