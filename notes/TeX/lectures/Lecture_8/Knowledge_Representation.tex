\documentclass[../../lecture_notes.tex]{subfiles}

\begin{document}

\noindent In the beginning of AI, there was a debate between symbolic and numeric representations.\\
Symbolic representation is now standard, though numeric representation is used in Bayesian Networks.\\
\\
Once knowledge representation was decided, acquisition needed to be decided.\\
	\indent We can model knowledge, whether procedurally or declaratively.\\
	\indent We can learn knowledge from information in the world.\\
The former approach is often used in AI, whereas the latter is used in ML.\\
This is changing however; progress in modern day requires more broad knowledge.\\
\\
We will be discussing the \textbf{\underline{classical model of logic}}

\begin{center} \begin{tikzpicture}
	\node[rectangle, draw, align=center] (1) {Statements\\in Logic};
	\node[rectangle, draw, align=center, right =of 1] (2) {Logical\\Deduction};	
	\node[align=center, below =of 2] (3) {Observations};	
	\node[align=center, right =of 2] (4) {Conclusions};
	\draw[->] (1.east) -- (2.west);
	\draw[->] (3.north) -- (2.south);
	\draw[->] (2.east) -- (4.west);
\end{tikzpicture} \end{center}

\begin{center} \begin{minipage}{0.5\textwidth}
\noindent Consider the example problem of the WumpusWorld:
\begin{enumerate} [itemsep=0mm]
	\item The grid contains a goal, pits, and a Wumpus
	\item Cells adjacent to pits are breezy
	\item Cells adjacent to the Wumpus smell
	\item The Wumpus and pits kill you
\end{enumerate} \end{minipage}%
\begin{minipage}{0.5\textwidth}
\begin{tabular}{ | c | c | c | }
	\hline
	 \text{      } & \text{      } & \text{      }  \\
	\hline
	P & & \\
	\hline
	Breeze & OK & \\
	\hline
	A & Stench & \text{  W  }\\
	\hline
\end{tabular} \end{minipage} \end{center}

\noindent The logic depends on two components:
\begin{enumerate} [itemsep=0mm]
	\item Prior Knowledge (Rule/Problem Structure)
	\item Observation (Learning/Breeze and Stench)
\end{enumerate}
This is a canonical \textbf{\underline{logical}} approach; 
	$\equiv$ if something is deduced, it MUST be true.\\
It is more complicated than many animals can do!
    
\subsection*{Propositional Logic}
\noindent There are two major components to propositional logic:
\begin{enumerate} [itemsep=0mm]
	\item \textbf{\underline{Syntax}} ($\equiv$ Grammar)
	\item \textbf{\underline{Semantics}} ($\equiv$ Meaning)
\end{enumerate}
\noindent Even if the syntax doesn’t match, semantics can tell if two statements are equal

\subsubsection*{Syntax}
\noindent A syntax consists of three elements:
\begin{enumerate} [itemsep=0mm]
	\item boolean variables $(X_1, ..., X_N)$
	\item logical connectives
		\begin{enumerate} [itemsep=0mm]
			\item $\land \equiv \text{AND}$
			\item $\lor \equiv \text{OR}$
			\item $\neg \equiv \text{NOT}$
			\item $\implies \equiv \text{IMPLIES}$
			\item $\iff \equiv \text{IFF}$
		\end{enumerate}
	\item Sentences
		\begin{enumerate} [itemsep=0mm]
			\item if S is a sentence, then $\neg S$ is a sentence.
			\item if $S_1 \& S_2$ are sentences, then each of the following are compound sentences:
				\begin{itemize} [itemsep=0mm]
					\item $S_1 \land S_2$
					\item $S_1 \lor S_2$
					\item $S_1 \implies S_2$
					\item $S_1 \iff S_2$
				\end{itemize}
		\end{enumerate}
\end{enumerate}

\noindent We use a few terms to refer to elements of a syntax:
\begin{itemize} [itemsep=0mm]
	\item $X, \neg X$ are called \textbf{\underline{literals}}
		\begin{itemize} [itemsep=0mm]
			\item X is the \textbf{\underline{positive literal}}
			\item $\neg X$ is the \textbf{\underline{negative literal}}
		\end{itemize}
	\item $X \land Y$ is called a \textbf{\underline{conjunction}}
		\begin{itemize} [itemsep=0mm]
			\item X, Y are called the \textbf{\underline{conjuncts}}
		\end{itemize}
	\item $X \lor Y$ is called a \textbf{\underline{disjunction}}
		\begin{itemize} [itemsep=0mm]
			\item X, Y are called the \textbf{\underline{disjuncts}}
		\end{itemize}
	\item $X \implies Y$ is called a \textbf{\underline{premise}}
		\begin{itemize} [itemsep=0mm]
			\item X is called the \textbf{\underline{premise antecedent}}
			\item Y is called the \textbf{\underline{implicant}}
		\end{itemize}
	\item $\neg Y \implies X$ is called the \textbf{\underline{contrapositive}} (in relation to the premise)
\end{itemize} \medskip

\noindent We have a few logical rules to work with sentences:
\begin{enumerate} [itemsep=0mm]
	\item $a \implies B = \neg a \lor B$
	\item $\neg(a \land B) = \neg a \lor \neg B$
	\item $\neg(a \lor B) = \neg a \land \neg B$
\end{enumerate} \medskip

\noindent Let’s try to capture the following state with logic:

\begin{center} \begin{minipage}{0.2\textwidth}
\begin{tabular}{ | c | c | c | }
	\hline
	& $B_1$ & \\
	\hline
	$B_2$ & P & $B_3$ \\
	\hline
	& $B_4$ & \\
	\hline
\end{tabular} 
\end{minipage}%
\begin{minipage}{0.8\textwidth}
\noindent Consider the example problem of the WumpusWorld:\\
\noindent We can represent this in (at least) two ways:
\begin{enumerate} [itemsep=0mm]
	\item $P \implies (B_1 \lor B_2 \lor B_3\lor B_4)$
	\item $P \implies (B1 \land B2 \land B3 \land B4)$
\end{enumerate}
\noindent The latter is \textbf{\underline{stronger}}, since it is more specific.\\
The former is true, but doesn’t model all we know.\\
This is a common problem when writing AI.
\end{minipage} \end{center}

\subsubsection*{Normal Forms}
\noindent Normal forms can be categorized in one of two ways:
\begin{enumerate} [itemsep=0mm]
	\item a grammar is \textbf{\underline{practical/restricted}} if there are logics it cannot represent.
	\item a grammar is \textbf{\underline{universal}} if it can represent any theoretical logic.
\end{enumerate}
The normal forms we will cover are:
\begin{enumerate} [itemsep=0mm]
	\item \textbf{\underline{Conjunctive Normal Form}}* \\
		$[(A \land \neg B) \lor (A \land \neg D \land E) \lor ...]$\\
	        We call a disjunction of literals a \textbf{\underline{clause}}.\\
		Therefore, this form is a \textbf{\underline{conjunction of clauses}}.
	\item \textbf{\underline{Disjunctive Normal Form}}* \\
		$[(A \lor \neg B) \land (A \lor \neg D \lor E) \lor ...]$\\
		We call a conjunction of literals a \textbf{\underline{term}}.\\
		Therefore, this form is a \textbf{\underline{disjunction of terms}}.
	\item \textbf{\underline{Horn Form}} \\
		$[(A \lor \neg B \lor \neg C) \lor (\neg A \lor \neg B \lor \neg C)]$\\
		A \textbf{\underline{horn clause}} is a clause with at most 1 positive literal.\\
		A clause $A \lor \neg B \lor \neg C$ can be written as $B \land C \implies A$\\
		$B \land C$ is called the \textbf{\underline{body}}; A is called the \textbf{\underline{head}}.
	\item \textbf{\underline{Negation Normal Form}}* \\
		$[(A \land \neg D \land E) \lor (A \lor \neg C \lor D) \land (A \land \neg B)]$\\
		Allows either clauses or terms, but only allows ($\neg$) on variables, not sentences.\\
		Are often represented as circuits.\\
		Is tractable iff all entries to all AND gates share no variables.\\
		This subset of NNFs are called \textbf{\underline{Decomposable (DNNF)}}.
\end{enumerate}  (* is used to represent grammars that are universal)\\
\noindent Fun fact: SAT on a CNF is hard but SAT on a DNF is easy.\\
Horn Form makes SAT linear, therefore Horn Form is \textbf{\underline{tractable}}.\\
\\
We can do these SAT problems in two ways:
\begin{enumerate} [itemsep=0mm]
	\item \textbf{\underline{Forward Chaining}} (data driven) 
		$\equiv$ iterate over the clauses; if the body is true, infer the head
	\item \textbf{\underline{Backward Chaining}} (Goal Driven)
            $\equiv$ recursively attempt to prove the goal to the head’s body
\end{enumerate}
\noindent In the ideal case, backward chaining is much faster than even linear!


\subsection*{Semantics}
\noindent Semantics are concerned with the notion of \textbf{\underline{worlds}}.\\
 \indent $\equiv$ a set containing a fixed truth value for all variables/preposition symbols
\\
We would like to know if a sentence holds in a given world.\\
If a holds in world w, we say $w \models a$ (equivalent to “world w contains a”).\\
\\
Consider the following example:

\begin{center} \begin{minipage}{0.2\textwidth}
\begin{tabular}{ | c || c | c | c | }
	\hline
	& E & A & B\\
	\hline\hline
	$W_1$ & T & T & T \\
	\hline
	$W_2$ & T & T & F \\
	\hline
	$W_3$ & T & F & T \\
	\hline
	$W_4$ & T & F & F \\
	\hline
	$W_5$ & F & T & T \\
	\hline
	$W_6$ & F & T & F \\
	\hline
	$W_7$ & F & F & T \\
	\hline
	$W_8$ & F & F & F \\
	\hline
\end{tabular} 
\end{minipage}%
\begin{minipage}{0.8\textwidth}
\noindent Which worlds do the following hold in?
\begin{itemize} [itemsep=0mm]
	\item $E ?\  \{1, 2, 3, 4\}$
	\item $\neg E ?\  \{5, 6, 7, 8\}$
	\item $\neg B ?\  \{3, 4, 7, 8\}$
	\item $\neg B \land \neg E ?\  \{7, 8\}$
	\item $A ?\  \{1, 3, 5, 7\}$
	\item $((\neg E \land \neg B) \lor A) ?\ \{1, 3, 5, 7, 8\}$
	\item $((E \lor B) \implies A )?\  \{1, 3, 5, 7, 8\}$
\end{itemize}
Therefore, \begin{itemize} [itemsep=0mm]
	\item $ W_1 \lor W_3 \lor W_5 \lor W_7 \lor W_8 \models (E \lor B) \implies A $
	\item $ W_2 \lor W_4 \lor W_6 \not\models (E \lor B) \implies A $
\end{itemize}
\end{minipage} \end{center}

\noindent We can thus derive that for sets of worlds S and T, if $S \models a \ \&\&\  T \models b$, then 
\begin{enumerate} [itemsep=0mm]
	\item $S \cap T \models (a \land b) $
	\item $S \cup T \models (a \lor b)$
	\item $S / T \models (a \land \neg b)$
\end{enumerate} 
\noindent If we thus assert the property $(a \land b)$, we can prune the set of worlds down to $S \cap T$.\\
If we get to one world, we know all; if we get to none, we have an inconsistency.\\
We can use these properties to build a pretty effective SAT Solver.\\

\noindent We denote the \textbf{\underline{meaning/model}} of $\alpha M(\alpha)$ 
	and define it by $M(\alpha) = \{w | w \models \alpha\}$.\\
Thus we should be able to translate the following easily:
\begin{enumerate} [itemsep=0mm]
	\item $\alpha \text{ is equivalent to } \beta \rightarrow M(\alpha) = M(\beta)$
	\item $\alpha \text{ is contradictory } \rightarrow M(\alpha) = \{\}$
	\item $\alpha \text{ is a \textbf{\underline{tautology}}/is valid } \rightarrow M(\alpha) = \{w\}$
	\item $\alpha \ \&\  \beta \text{ are mutually exclusive } \rightarrow M(\alpha) \cap M(\beta) = \{\}$
	\item $\alpha \text{ implies } \beta \  (\alpha \implies \beta) \rightarrow M(\alpha) \subset M(\beta)$
\end{enumerate}

\end{document}