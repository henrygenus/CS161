\documentclass[../../lecture_notes.tex]{subfiles}

\begin{document}

\noindent We can now expand on our earlier search problem model:

\begin{center} \begin{tikzpicture}
	\node [rectangle, draw, text width=3.7cm] (1) {Search Problem \begin{enumerate} [itemsep=0mm]
				\item Initial State \item Goal Test \item Successor Function \item Heuristic*
			\end{enumerate} *for informed search};
	\node [rectangle, draw, align=center, right =of 1] (2) {Search\\Engine};
	\node [rectangle, draw, text width=3.6cm, below=of 2] (3) {Search Strategy \begin{enumerate} [itemsep=0mm]
				\item Uninformed/Blind \item Informed/Heuristic \end{enumerate}};
	\node [right =of 2] (4) {Solution};
	\draw [->] (1.east) -- (2.west);
	\draw [->] (3.north) -- (2.south);
	\draw [->] (2.east) -- (4.west);
\end{tikzpicture} \end{center} \medskip

\noindent We will begin our discussion of heuristic searches by discussing best-first search.\\
This is uninformed, but will lead us naturally into heuristics.

\subsection*{Uniform-Cost Search (UCS)}
\begin{itemize} [itemsep=0mm]
	\item uninformed generalization of BFS to weighted graphs
	\item expands based on contours of uniform cost and shape
	\item we goal check on expansion and not generation or our solution may be suboptimal
	\item we expand according to the function g(n) := cost of actions from initial state to node n
\end{itemize}
\noindent Properties:
	\begin{enumerate} [itemsep=0mm]
		\item complete? YES
		\item optimal? YES
		\item time? $O(b^{ceil(C*/E)})$
		\item space?  $O(b^{ceil(C*/E)})$
	\end{enumerate}
	where E = minimal action cost \& C* = optimal solution cost

\begin{center} \begin{tikzpicture}
	\node[circle, draw, text width=1cm, align=center] (S) {\begin{tikzpicture} 
		\node [circle, draw] {S}; \end{tikzpicture}};
	\node[circle, draw, align=center, text width=1cm, above right =of S] (A) {A};
	\node[circle, draw, align=center, text width=1cm, below right =of S] (C) {C};
	\node[circle, draw, align=center, text width=1cm, right =of S] (B) {B};
	\node[circle, draw, align=center, text width=1cm, right =of B] (G) {G};
	\draw [-] (S.north east) -- node [align=center, left] {1} (A.south west);
	\draw [-] (S.east) -- node [align=center, above] {5} (B.west);
	\draw [-] (S.south east) -- node [align=center, left] {10} (C.north west);
	\draw [-] (B.east) -- node [align=center, above] {5} (G.west);
	\draw [-] (A.south east) -- node [align=center, above] {10} (G.north west);
	\draw [-] (C.north east) -- node [align=center, right] {5} (G.south west);
	\node [right=6cm of A] {S}
		child {node {A}
			child {node{G}
				edge from parent node [left] {10}}
			edge from parent node [left] {1}}
		child {node {B}
			child {node [circle, draw] {G}
				edge from parent node[left]  {5}}
			edge from parent node [left] {5}}
		child {node {C}
			edge from parent node [right] {15}};
\end{tikzpicture} \end{center}
\noindent Unfortunately, this algorithm tends to wander a bit; we want a smarter algorithm!

\subsection*{Greedy Search}
\begin{itemize} [itemsep=0mm]
	\item a modified UFS based on an estimate of the distance to the goal state h(n)
	\item h is an \textbf{\underline{admissible}} function $\equiv h(G) = 0 $
	\item h is a \textbf{\underline{consistent}} function $\equiv h(n) \leq \text{ actual cost }$\\
		This is stricter than the admissible requirement, but is hard to avoid in practice.
\end{itemize}

\noindent Properties:
\begin{enumerate} [itemsep=0mm]
	\item complete? NO (for example: A —1— B —2— C)
	\item optimal? NO
	\item time? $O(b^m)$
	\item space? $O(b^m)$
\end{enumerate} \medskip

\noindent Let’s compare our two algorithms:\\
\indent UCS:\
	\indent g(n): actual cost to get to n from initial state
	\begin{itemize} [itemsep=0mm]
		\item optimal
		\item conservative
		\item slow
	\end{itemize}
\indent Greedy:\
        \indent h(n) estimate of cost to get to final state from n
        \begin{itemize} [itemsep=0mm]
		\item non-optimal
		\item aggressive
		\item fast
	\end{itemize}
\noindent Neither of these has all the properties we want; can we get the best properties of both?\\
It turns out YES: we just have to add them directly!\\
\indent f(n) = g(n) + h(n) estimates the total cost \& is admissible (provided h(n) is admissible)\\
This leads us to a very important algorithm:

\subsection*{$A^*$ Search}
\begin{itemize}[itemsep=0mm]
	\item UCS based on f(n) = g(n) + h(n)
	\item forms contours which slim approaching goal
	\item prunes nodes outside contours
	\item we can prove that this algorithm is optimal:
\end{itemize} \medskip

\noindent Let’s discuss the choice of heuristic: can we find a good heuristic for every problem?\\
	\indent h(n) = 0 works for every problem, but this makes the algorithm UCS!\\
Therefore, we want the maximum \underline{admissible} heuristic for a given problem.\\
\\
We will now consider a concrete example: 8 PUZZLE\\
We have two heuristics we would like to consider:\\
\indent $h_1(n)$ = \# pieces out of place \\
\indent $h_2(n)$ = Manhattan Distance $\equiv$ horizontal + vertical distance \\
$h_2(n) \leq h_1(n)$ for all n, so we say $h_2$ dominates $h_1$\\
Clearly $h_2$ is the better choice, but how much better can it really be?\\
\\
We use two properties to evaluate search $A*$ search algorithms
\begin{enumerate} [itemsep=0mm]
	\item effective branching factor ($b^*$) := avg branches per node
	\item node count $(N) = 1 + (b^*)^0 + (b^*)^2 + … + (b^*)^d$
\end{enumerate} \medskip

\begin{tabular} { c | c c c }
d & IDS & $A^*(h_1)$  & $A^*(h_2)$\\
\hline
4  & N = 112; $b^*$ = 2.35  & N = 13; $b^*$ = 1.48 & N = 12; $b^*$ = 1.45\\
6 & N = 680; $b^*$ = 2.87 & N = 20; $b^*$ = 1.34 & N = 18; $b^*$ = 1.30\\
8 & N = 6384; $b^*$ = 2.73 & N = 39; $b^*$ = 1.33 & N = 25; $b^*$ 1.24\\
10 & N = 47,127 & N = 93 & N = 39\\
12 & N = 3,644,035 & N = 227 & N = 73 
\end{tabular} \medskip

\noindent Clearly, $A^*$ is much more efficient, and h2 is much more efficient than h1;\\
\indent how do we formally evaluate this?\\
\indent \indent time cost = $O(b^\Delta)$, for absolute error $\Delta = h(n) - h^*$\\
\indent \indent $\implies$ hypothetical min $O(h^\epsilon)$ , for fractional error $\epsilon = (h* - h) / h^*$ is the

\end{document}